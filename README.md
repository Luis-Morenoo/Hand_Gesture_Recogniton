# Hand_Gesture_Recogniton

Welcome to the Hand Gesture Recognition project repository. This project utilizes Python along with the OpenCV, MediaPipe, TensorFlow Keras libraries, and a pre-trained model for real-time recognition of hand gestures.

## Overview

Gesture recognition is a fast-expanding area of research in computer science and engineering that attempts to make it possible for machines to recognize and comprehend human motions. It entails creating algorithms and technology that can recognize and examine human physical movements, including hand gestures, body movements, and face expressions. There are numerous uses for gesture recognition, including in robotics, gaming, healthcare, and security. The advancement of machine learning and deep learning algorithms has substantially increased the reliability and accuracy of gesture recognition systems, making them more practical and effective in a variety of real-world applications. Despite the many obstacles still in the way, gesture recognition has the power to completely change how people interact with technology, allowing for more intuitive and organic forms of communication.

## Key Features

- **Real-Time Gesture Recognition:** The project can identify and classify hand gestures in real-time, allowing for interactive applications.
- **OpenCV Integration:** OpenCV is utilized for capturing and processing video frames from a webcam or camera source.
- **MediaPipe Hand Tracking:** The MediaPipe library provides hand tracking capabilities, making it easier to locate and analyze hand gestures.
- **Deep Learning Model:** TensorFlow Keras is used to train and deploy a deep learning model for gesture classification.
- **Customizable Gestures:** The system can be extended to recognize custom hand gestures, making it adaptable for various use cases.

## Getting Started

To get started with this project, follow these steps:

1. Clone the repository: https://github.com/Luis-Morenoo/Hand_Gesture_Recogniton/tree/main
2. 2. Run the "Second attempt.ipynb" Python script to start real-time gesture recognition
  
How It Works

    The project captures video frames from a camera source using OpenCV.
    MediaPipe hand tracking is applied to locate and track the user's hand within the video frames.
    The deep learning model, pre-trained or custom, is used to classify the hand gestures.
    The recognized gestures are then processed and can be used for various applications, such as controlling a presentation or a game.

Customization

To customize this project for your specific needs:

    Train a custom deep learning model on your own dataset for specific gestures.
    Modify the gesture recognition logic to trigger different actions based on recognized gestures.
    Experiment with different MediaPipe and OpenCV parameters for improved hand tracking and gesture recognition.

Demo

https://youtu.be/w7WpllxGFTA

Contributions to this project are welcome! If you have ideas for improvements, feature requests, or bug fixes, please feel free to fork the repository and submit pull requests.
License

This project is licensed under the MIT License. You are free to use, modify, and distribute this code for educational or personal purposes.
Contact

Feel free to reach out if you have any questions, suggestions, or feedback. Happy coding!
